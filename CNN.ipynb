{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, RegressionMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, RFormula\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import atexit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import sgd\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils as utils\n",
    "from keras.layers import Dropout, Dense, Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add your first Convolution layer\n",
    "* We first specify that the output will have 32 feature maps \n",
    "* We next specifiy a 3x3 Kernel / map\n",
    "* We set padding to same which means it will not dorp off the edges of the images (look at Stanfort cheat sheet on teams)\n",
    "* The input size is 32x32 and has 3 channels (RGB)\n",
    "* Activation is Relu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  here we jsut set the input size, kernel size , padding and activation. You can also set the stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3),padding='valid', activation= 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "Normally pooling is used for:\n",
    "* Dimensionality reduction \n",
    "* dectecting edges, eyes, noses, corners etc. \n",
    "* FUNCTION = reduce the number of parameters and spatial size in the network \n",
    "\n",
    "#### Done in 2 ways:\n",
    "* Max pooling :  States maximum output in rectangular neighbourhood \n",
    "* Average pooling: Average output in rectangular neighbourhood \n",
    "* reduces amount of pixels, makes image smaller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stride\n",
    "* Modifies movement of videos and images \n",
    "* works in conjunction with padding \n",
    "* Stride 1 = will move one pixel or unit at a time \n",
    "* Stride 2 = will move two pixles or units at a time \n",
    "* dilutes how many steops can skipped while scanning features horizontally and vertically on the image\n",
    "* padding + stride impacts data size, Padding is essential in stride - without padding the next layer will reduce the data size \n",
    "\n",
    "##### Works like this:\n",
    "* starts with the filter in the top left corner and calcuales the value of the first node, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer\n",
    "* Summation of all the input and weights which acn determine the final predication \n",
    "* output of last pooling layer \n",
    "* connectes each node in all the layers (every neuron in one layer to neuros in other layers)\n",
    "* Performs classification based ont he features extracted by the previous layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THUS CNN's have to categories : Feature Extraction and Classification based on the extracted features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Linear Layers\n",
    "*  Activiation function applied in last layer ( as you know from ANN) because it gives the final number we use to classify\n",
    "*  Multiclass uses Softmax\n",
    "*  RELU + TRIGGER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[158, 112,  49],\n",
       "         [159, 111,  47],\n",
       "         [165, 116,  51],\n",
       "         ...,\n",
       "         [137,  95,  36],\n",
       "         [126,  91,  36],\n",
       "         [116,  85,  33]],\n",
       "\n",
       "        [[152, 112,  51],\n",
       "         [151, 110,  40],\n",
       "         [159, 114,  45],\n",
       "         ...,\n",
       "         [136,  95,  31],\n",
       "         [125,  91,  32],\n",
       "         [119,  88,  34]],\n",
       "\n",
       "        [[151, 110,  47],\n",
       "         [151, 109,  33],\n",
       "         [158, 111,  36],\n",
       "         ...,\n",
       "         [139,  98,  34],\n",
       "         [130,  95,  34],\n",
       "         [120,  89,  33]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 68, 124, 177],\n",
       "         [ 42, 100, 148],\n",
       "         [ 31,  88, 137],\n",
       "         ...,\n",
       "         [ 38,  97, 146],\n",
       "         [ 13,  64, 108],\n",
       "         [ 40,  85, 127]],\n",
       "\n",
       "        [[ 61, 116, 168],\n",
       "         [ 49, 102, 148],\n",
       "         [ 35,  85, 132],\n",
       "         ...,\n",
       "         [ 26,  82, 130],\n",
       "         [ 29,  82, 126],\n",
       "         [ 20,  64, 107]],\n",
       "\n",
       "        [[ 54, 107, 160],\n",
       "         [ 56, 105, 149],\n",
       "         [ 45,  89, 132],\n",
       "         ...,\n",
       "         [ 24,  77, 124],\n",
       "         [ 34,  84, 129],\n",
       "         [ 21,  67, 110]]],\n",
       "\n",
       "\n",
       "       [[[235, 235, 235],\n",
       "         [231, 231, 231],\n",
       "         [232, 232, 232],\n",
       "         ...,\n",
       "         [233, 233, 233],\n",
       "         [233, 233, 233],\n",
       "         [232, 232, 232]],\n",
       "\n",
       "        [[238, 238, 238],\n",
       "         [235, 235, 235],\n",
       "         [235, 235, 235],\n",
       "         ...,\n",
       "         [236, 236, 236],\n",
       "         [236, 236, 236],\n",
       "         [235, 235, 235]],\n",
       "\n",
       "        [[237, 237, 237],\n",
       "         [234, 234, 234],\n",
       "         [234, 234, 234],\n",
       "         ...,\n",
       "         [235, 235, 235],\n",
       "         [235, 235, 235],\n",
       "         [234, 234, 234]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 87,  99,  89],\n",
       "         [ 43,  51,  37],\n",
       "         [ 19,  23,  11],\n",
       "         ...,\n",
       "         [169, 184, 179],\n",
       "         [182, 197, 193],\n",
       "         [188, 202, 201]],\n",
       "\n",
       "        [[ 82,  96,  82],\n",
       "         [ 46,  57,  36],\n",
       "         [ 36,  44,  22],\n",
       "         ...,\n",
       "         [174, 189, 183],\n",
       "         [185, 200, 196],\n",
       "         [187, 202, 200]],\n",
       "\n",
       "        [[ 85, 101,  83],\n",
       "         [ 62,  75,  48],\n",
       "         [ 58,  67,  38],\n",
       "         ...,\n",
       "         [168, 183, 178],\n",
       "         [180, 195, 191],\n",
       "         [186, 200, 199]]],\n",
       "\n",
       "\n",
       "       [[[158, 190, 222],\n",
       "         [158, 187, 218],\n",
       "         [139, 166, 194],\n",
       "         ...,\n",
       "         [228, 231, 234],\n",
       "         [237, 239, 243],\n",
       "         [238, 241, 246]],\n",
       "\n",
       "        [[170, 200, 229],\n",
       "         [172, 199, 226],\n",
       "         [151, 176, 201],\n",
       "         ...,\n",
       "         [232, 232, 236],\n",
       "         [246, 246, 250],\n",
       "         [246, 247, 251]],\n",
       "\n",
       "        [[174, 201, 225],\n",
       "         [176, 200, 222],\n",
       "         [157, 179, 199],\n",
       "         ...,\n",
       "         [230, 229, 232],\n",
       "         [250, 249, 251],\n",
       "         [245, 244, 247]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 31,  40,  45],\n",
       "         [ 30,  39,  44],\n",
       "         [ 26,  35,  40],\n",
       "         ...,\n",
       "         [ 37,  40,  46],\n",
       "         [  9,  13,  14],\n",
       "         [  4,   7,   5]],\n",
       "\n",
       "        [[ 23,  34,  39],\n",
       "         [ 27,  38,  43],\n",
       "         [ 25,  36,  41],\n",
       "         ...,\n",
       "         [ 19,  20,  24],\n",
       "         [  4,   6,   3],\n",
       "         [  5,   7,   3]],\n",
       "\n",
       "        [[ 28,  41,  47],\n",
       "         [ 30,  43,  50],\n",
       "         [ 32,  45,  52],\n",
       "         ...,\n",
       "         [  5,   6,   8],\n",
       "         [  4,   5,   3],\n",
       "         [  7,   8,   7]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 20,  15,  12],\n",
       "         [ 19,  14,  11],\n",
       "         [ 15,  14,  11],\n",
       "         ...,\n",
       "         [ 10,   9,   7],\n",
       "         [ 12,  11,   9],\n",
       "         [ 13,  12,  10]],\n",
       "\n",
       "        [[ 21,  16,  13],\n",
       "         [ 20,  16,  13],\n",
       "         [ 18,  17,  12],\n",
       "         ...,\n",
       "         [ 10,   9,   7],\n",
       "         [ 10,   9,   7],\n",
       "         [ 12,  11,   9]],\n",
       "\n",
       "        [[ 21,  16,  13],\n",
       "         [ 21,  17,  12],\n",
       "         [ 20,  18,  11],\n",
       "         ...,\n",
       "         [ 12,  11,   9],\n",
       "         [ 12,  11,   9],\n",
       "         [ 13,  12,  10]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 33,  25,  13],\n",
       "         [ 34,  26,  15],\n",
       "         [ 34,  26,  15],\n",
       "         ...,\n",
       "         [ 28,  25,  52],\n",
       "         [ 29,  25,  58],\n",
       "         [ 23,  20,  42]],\n",
       "\n",
       "        [[ 33,  25,  14],\n",
       "         [ 34,  26,  15],\n",
       "         [ 34,  26,  15],\n",
       "         ...,\n",
       "         [ 27,  24,  52],\n",
       "         [ 27,  24,  56],\n",
       "         [ 25,  22,  47]],\n",
       "\n",
       "        [[ 31,  23,  12],\n",
       "         [ 32,  24,  13],\n",
       "         [ 33,  25,  14],\n",
       "         ...,\n",
       "         [ 24,  23,  50],\n",
       "         [ 26,  23,  53],\n",
       "         [ 25,  20,  47]]],\n",
       "\n",
       "\n",
       "       [[[ 25,  40,  12],\n",
       "         [ 15,  36,   3],\n",
       "         [ 23,  41,  18],\n",
       "         ...,\n",
       "         [ 61,  82,  78],\n",
       "         [ 92, 113, 112],\n",
       "         [ 75,  89,  92]],\n",
       "\n",
       "        [[ 12,  25,   6],\n",
       "         [ 20,  37,   7],\n",
       "         [ 24,  36,  15],\n",
       "         ...,\n",
       "         [115, 134, 138],\n",
       "         [149, 168, 177],\n",
       "         [104, 117, 131]],\n",
       "\n",
       "        [[ 12,  25,  11],\n",
       "         [ 15,  29,   6],\n",
       "         [ 34,  40,  24],\n",
       "         ...,\n",
       "         [154, 172, 182],\n",
       "         [157, 175, 192],\n",
       "         [116, 129, 151]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[100, 129,  81],\n",
       "         [103, 132,  84],\n",
       "         [104, 134,  86],\n",
       "         ...,\n",
       "         [ 97, 128,  84],\n",
       "         [ 98, 126,  84],\n",
       "         [ 91, 121,  79]],\n",
       "\n",
       "        [[103, 132,  83],\n",
       "         [104, 131,  83],\n",
       "         [107, 135,  87],\n",
       "         ...,\n",
       "         [101, 132,  87],\n",
       "         [ 99, 127,  84],\n",
       "         [ 92, 121,  79]],\n",
       "\n",
       "        [[ 95, 126,  78],\n",
       "         [ 95, 123,  76],\n",
       "         [101, 128,  81],\n",
       "         ...,\n",
       "         [ 93, 124,  80],\n",
       "         [ 95, 123,  81],\n",
       "         [ 92, 120,  80]]],\n",
       "\n",
       "\n",
       "       [[[ 73,  78,  75],\n",
       "         [ 98, 103, 113],\n",
       "         [ 99, 106, 114],\n",
       "         ...,\n",
       "         [135, 150, 152],\n",
       "         [135, 149, 154],\n",
       "         [203, 215, 223]],\n",
       "\n",
       "        [[ 69,  73,  70],\n",
       "         [ 84,  89,  97],\n",
       "         [ 68,  75,  81],\n",
       "         ...,\n",
       "         [ 85,  95,  89],\n",
       "         [ 71,  82,  80],\n",
       "         [120, 133, 135]],\n",
       "\n",
       "        [[ 69,  73,  70],\n",
       "         [ 90,  95, 100],\n",
       "         [ 62,  71,  74],\n",
       "         ...,\n",
       "         [ 74,  81,  70],\n",
       "         [ 53,  62,  54],\n",
       "         [ 62,  74,  69]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[123, 128,  96],\n",
       "         [132, 132, 102],\n",
       "         [129, 128, 100],\n",
       "         ...,\n",
       "         [108, 107,  88],\n",
       "         [ 62,  60,  55],\n",
       "         [ 27,  27,  28]],\n",
       "\n",
       "        [[115, 121,  91],\n",
       "         [123, 124,  95],\n",
       "         [129, 126,  99],\n",
       "         ...,\n",
       "         [115, 116,  94],\n",
       "         [ 66,  65,  59],\n",
       "         [ 27,  27,  27]],\n",
       "\n",
       "        [[116, 120,  90],\n",
       "         [121, 122,  94],\n",
       "         [129, 128, 101],\n",
       "         ...,\n",
       "         [116, 115,  94],\n",
       "         [ 68,  65,  58],\n",
       "         [ 27,  26,  26]]]], dtype=uint8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we deviding by 255 : https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , X_test = X.astype('float32')/255.0, X_test.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our labels to categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise sequential mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Drop out rate (Regularization)\n",
    "https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/#:~:text=A%20good%20value%20for%20dropout,rate%2C%20such%20as%20of%200.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another layer with padding set to valid : https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t#:~:text=To%20sum%20up%2C%20'valid',same'%20padding%20means%20using%20padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a max pooling layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the data so that we can classify :https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening\n",
    "* our data is currently in a matrix \n",
    "* we need it in a stack \n",
    "* this makes the final pooled layer a stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the dense layer : which will classify for us, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(512, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more dropout to this layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=sgd(momentum=0.5, decay=0.0004), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the algorithm with 25 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 41s 821us/step - loss: 2.2145 - accuracy: 0.1763 - val_loss: 2.0726 - val_accuracy: 0.2907\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 1.9744 - accuracy: 0.2961 - val_loss: 1.9009 - val_accuracy: 0.3427\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 1.8739 - accuracy: 0.3404 - val_loss: 1.8503 - val_accuracy: 0.3575\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 1.8050 - accuracy: 0.3649 - val_loss: 1.7626 - val_accuracy: 0.3880\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 1.7539 - accuracy: 0.3808 - val_loss: 1.7130 - val_accuracy: 0.4021\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 39s 785us/step - loss: 1.7065 - accuracy: 0.4009 - val_loss: 1.6913 - val_accuracy: 0.4152\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 40s 791us/step - loss: 1.6706 - accuracy: 0.4106 - val_loss: 1.6375 - val_accuracy: 0.4324\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 40s 790us/step - loss: 1.6309 - accuracy: 0.4278 - val_loss: 1.5989 - val_accuracy: 0.4396\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 1.6049 - accuracy: 0.4349 - val_loss: 1.5743 - val_accuracy: 0.4516\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 1.5817 - accuracy: 0.4430 - val_loss: 1.5727 - val_accuracy: 0.4459\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 1.5587 - accuracy: 0.4503 - val_loss: 1.5314 - val_accuracy: 0.4587\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 39s 785us/step - loss: 1.5356 - accuracy: 0.4595 - val_loss: 1.5237 - val_accuracy: 0.4666\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 1.5177 - accuracy: 0.4637 - val_loss: 1.5100 - val_accuracy: 0.4722\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 1.5019 - accuracy: 0.4725 - val_loss: 1.4760 - val_accuracy: 0.4766\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 39s 787us/step - loss: 1.4854 - accuracy: 0.4777 - val_loss: 1.4617 - val_accuracy: 0.4903\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 1.4735 - accuracy: 0.4781 - val_loss: 1.4342 - val_accuracy: 0.4997\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 40s 790us/step - loss: 1.4563 - accuracy: 0.4848 - val_loss: 1.4416 - val_accuracy: 0.4914\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 1.4458 - accuracy: 0.4899 - val_loss: 1.4551 - val_accuracy: 0.4841\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 1.4315 - accuracy: 0.4965 - val_loss: 1.3987 - val_accuracy: 0.5100\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 1.4196 - accuracy: 0.4981 - val_loss: 1.3963 - val_accuracy: 0.5098\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 39s 787us/step - loss: 1.4070 - accuracy: 0.5042 - val_loss: 1.3834 - val_accuracy: 0.5168\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 39s 785us/step - loss: 1.3965 - accuracy: 0.5077 - val_loss: 1.3693 - val_accuracy: 0.5224\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 40s 792us/step - loss: 1.3858 - accuracy: 0.5091 - val_loss: 1.3601 - val_accuracy: 0.5245\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 39s 790us/step - loss: 1.3718 - accuracy: 0.5176 - val_loss: 1.3625 - val_accuracy: 0.5245\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 1.3650 - accuracy: 0.5184 - val_loss: 1.3558 - val_accuracy: 0.5279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f368c2d5ca0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_data=(X_test, y_test), epochs=25,  batch_size=512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('azureml_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
